{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher/outputs/Qwen3-8B_sglang/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher/outputs/Qwen3-8B_sglang/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher/outputs/Qwen3-8B_sglang/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 3.33, "best_pass_at_1": 10.0, "pass_at_3": 10.0}, "individual": {"Round1_Pass@1": 10.1, "Round2_Pass@1": 0.0, "Round3_Pass@1": 0.0}, "statistics": {"extra_length": 0.0, "num_invalid": 94.0, "avg_action": 0.614, "avg_visit_action": 0.0, "avg_search_action": 0.0, "avg_other_action": 0.614, "avg_ans_length": 260.246, "avg_think_length": 3351.271, "avg_tool_calls_per_question": 0.614, "avg_assistant_tokens_per_question": 1603.644, "avg_assistant_tokens_per_message": 1360.672, "termination_freq": {"answer": 0.53, "unknown": 0.47}, "avg_tool_calls_per_question_correctly_solved": 2.2, "avg_assistant_tokens_per_question_correctly_solved": 2649.45}}
{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher/outputs/Qwen3-30B-A3B-Thinking-2507_sglang/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher/outputs/Qwen3-30B-A3B-Thinking-2507_sglang/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher/outputs/Qwen3-30B-A3B-Thinking-2507_sglang/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 3.0, "best_pass_at_1": 9.0, "pass_at_3": 9.0}, "individual": {"Round1_Pass@1": 9.0, "Round2_Pass@1": 0.0, "Round3_Pass@1": 0.0}, "statistics": {"extra_length": 0.0, "num_invalid": 0.333, "avg_action": 0.71, "avg_visit_action": 0.0, "avg_search_action": 0.03, "avg_other_action": 0.68, "avg_ans_length": 91.665, "avg_think_length": 16260.545, "avg_tool_calls_per_question": 0.71, "avg_assistant_tokens_per_question": 6539.512, "avg_assistant_tokens_per_message": 3715.188, "termination_freq": {"answer not found": 0.002, "answer": 0.998}, "avg_tool_calls_per_question_correctly_solved": 2.111, "avg_assistant_tokens_per_question_correctly_solved": 4978.222}}
{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher/outputs/Qwen3-14B_sglang/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher/outputs/Qwen3-14B_sglang/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher/outputs/Qwen3-14B_sglang/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 3.5, "best_pass_at_1": 9.5, "pass_at_3": 9.5}, "individual": {"Round1_Pass@1": 9.5, "Round2_Pass@1": 0.5, "Round3_Pass@1": 0.5}, "statistics": {"extra_length": 0.0, "num_invalid": 121.667, "avg_action": 0.713, "avg_visit_action": 0.0, "avg_search_action": 0.0, "avg_other_action": 0.713, "avg_ans_length": 168.005, "avg_think_length": 2129.961, "avg_tool_calls_per_question": 0.713, "avg_assistant_tokens_per_question": 1171.375, "avg_assistant_tokens_per_message": 1065.816, "termination_freq": {"answer": 0.392, "answer not found": 0.002, "unknown": 0.597, "exceed available llm calls": 0.01}, "avg_tool_calls_per_question_correctly_solved": 2.095, "avg_assistant_tokens_per_question_correctly_solved": 1866.286}}
{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher/outputs/Qwen3-32B_sglang/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher/outputs/Qwen3-32B_sglang/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher/outputs/Qwen3-32B_sglang/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 2.33, "best_pass_at_1": 7.0, "pass_at_3": 7.0}, "individual": {"Round1_Pass@1": 7.0, "Round2_Pass@1": 0.0, "Round3_Pass@1": 0.0}, "statistics": {"extra_length": 0.0, "num_invalid": 12.667, "avg_action": 1.6, "avg_visit_action": 0.0, "avg_search_action": 0.0, "avg_other_action": 1.6, "avg_ans_length": 617.203, "avg_think_length": 7208.05, "avg_tool_calls_per_question": 1.6, "avg_assistant_tokens_per_question": 4471.977, "avg_assistant_tokens_per_message": 551.645, "termination_freq": {"answer": 0.937, "exceed available llm calls": 0.063}, "avg_tool_calls_per_question_correctly_solved": 2.143, "avg_assistant_tokens_per_question_correctly_solved": 2470.857}}
{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher-v1110/outputs/Qwen3-8B_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher-v1110/outputs/Qwen3-8B_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher-v1110/outputs/Qwen3-8B_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 10.17, "best_pass_at_1": 10.5, "pass_at_3": 10.5}, "individual": {"Round1_Pass@1": 10.0, "Round2_Pass@1": 10.5, "Round3_Pass@1": 10.0}, "statistics": {"extra_length": 0.0, "num_invalid": 0.0, "avg_action": 4.85, "avg_visit_action": 0.0, "avg_search_action": 0.0, "avg_other_action": 4.85, "avg_ans_length": 1338.285, "avg_think_length": 4112.358, "avg_tool_calls_per_question": 4.85, "avg_assistant_tokens_per_question": 9816.635, "avg_assistant_tokens_per_message": 889.591, "avg_total_token_consumption": 25489.94, "termination_freq": {"success": 1.0}, "avg_tool_calls_per_question_correctly_solved": 4.787, "avg_assistant_tokens_per_question_correctly_solved": 9089.803, "avg_total_token_consumption_correctly_solved": 23712.344}}
{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher-v1110/outputs/Qwen3-30B-A3B-Thinking-2507_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher-v1110/outputs/Qwen3-30B-A3B-Thinking-2507_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher-v1110/outputs/Qwen3-30B-A3B-Thinking-2507_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 5.08, "best_pass_at_1": 5.08, "pass_at_3": 5.08}, "individual": {"Round1_Pass@1": 5.08, "Round2_Pass@1": 5.08, "Round3_Pass@1": 5.08}, "statistics": {"extra_length": 37.0, "num_invalid": 6.0, "avg_action": 4.777, "avg_visit_action": 0.0, "avg_search_action": 0.036, "avg_other_action": 4.741, "avg_ans_length": 1211.315, "avg_think_length": 7966.169, "avg_tool_calls_per_question": 4.777, "avg_assistant_tokens_per_question": 19437.239, "avg_assistant_tokens_per_message": 1818.203, "avg_total_token_consumption": 39784.985, "termination_freq": {"success": 1.0}, "avg_tool_calls_per_question_correctly_solved": 4.7, "avg_assistant_tokens_per_question_correctly_solved": 19281.7, "avg_total_token_consumption_correctly_solved": 38943.6}}
{"dataset": "browsecomp_en_full", "files": {"round1": "../inference-team-researcher-v1110/outputs/Qwen3-14B_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter1.jsonl", "round2": "../inference-team-researcher-v1110/outputs/Qwen3-14B_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter2.jsonl", "round3": "../inference-team-researcher-v1110/outputs/Qwen3-14B_TeamResearcher/eval_data/browsecomp-plus-part.jsonl/iter3.jsonl"}, "overall": {"avg_pass_at_3": 7.0, "best_pass_at_1": 7.0, "pass_at_3": 7.5}, "individual": {"Round1_Pass@1": 7.0, "Round2_Pass@1": 7.0, "Round3_Pass@1": 7.0}, "statistics": {"extra_length": 0.0, "num_invalid": 0.0, "avg_action": 5.655, "avg_visit_action": 0.0, "avg_search_action": 0.01, "avg_other_action": 5.645, "avg_ans_length": 1366.985, "avg_think_length": 3159.874, "avg_tool_calls_per_question": 5.655, "avg_assistant_tokens_per_question": 7757.25, "avg_assistant_tokens_per_message": 675.424, "avg_total_token_consumption": 23148.365, "termination_freq": {"success": 1.0}, "avg_tool_calls_per_question_correctly_solved": 5.69, "avg_assistant_tokens_per_question_correctly_solved": 7432.333, "avg_total_token_consumption_correctly_solved": 23536.143}}
